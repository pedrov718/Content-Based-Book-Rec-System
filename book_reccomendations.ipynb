{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrov718/Content-Based-Book-Rec-System/blob/main/book_reccomendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlGgnvfj79R8",
        "outputId": "6c1e992f-c089-4948-8eee-6392b8115474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ahHQOMF79R-"
      },
      "outputs": [],
      "source": [
        "df  = pd.read_csv('/content/drive/MyDrive/Book Rec/books_with_blurbs.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDGvHv__79R-"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLUla0u079R-"
      },
      "outputs": [],
      "source": [
        "df['Blurb'][10:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8O4DSRj79R-"
      },
      "outputs": [],
      "source": [
        "# Load spacy\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "def clean_string(text, stem=\"None\"):\n",
        "\n",
        "    final_string = \"\"\n",
        "\n",
        "    # Make lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove line breaks\n",
        "    text = re.sub(r'\\n', '', text)\n",
        "\n",
        "    # Remove puncuation\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    #Remove stop words\n",
        "    text = text.split()\n",
        "\n",
        "    #Remove numbers\n",
        "    text_filtered = [re.sub(r'\\w*\\d\\w*', '', word) for word in text]\n",
        "\n",
        "    # Stem or Lemmatize\n",
        "    if stem == 'Stem':\n",
        "        stemmer = PorterStemmer() \n",
        "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
        "    elif stem == 'Lem':\n",
        "        lem = WordNetLemmatizer()\n",
        "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
        "    elif stem == 'Spacy':\n",
        "        text_filtered = nlp(' '.join(text_filtered))\n",
        "        text_stemmed = [y.lemma_ for y in text_filtered]\n",
        "    else:\n",
        "        text_stemmed = text_filtered\n",
        "\n",
        "    final_string = ' '.join(text_stemmed)\n",
        "\n",
        "    return final_string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQdeiD6j79R_"
      },
      "outputs": [],
      "source": [
        "print(\"Cleaning train data...\\n\")\n",
        "\n",
        "df[\"blurb_clean\"] = df['Blurb'].apply(lambda x: clean_string(x, stem='Spacy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85K4qCwD79R_"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bh3dupB79R_"
      },
      "outputs": [],
      "source": [
        "df['Title_lower'] = df['Title'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEbwj1nx79SA"
      },
      "outputs": [],
      "source": [
        "df['blurb_clean_title'] =  df['Title_lower'] +  ' ' + df['blurb_clean']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RbrbPNn79SA"
      },
      "outputs": [],
      "source": [
        "df['blurb_clean_title'][10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cvCgzyhj9ml2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/Book Rec/books_with_blurbs_clean.csv')"
      ],
      "metadata": {
        "id": "PFA3HeEFf4d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W7Lo8UXGva0w",
        "outputId": "5473d6d9-fdd4-4984-ab6d-8ad0ee4d9626",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run locally here"
      ],
      "metadata": {
        "id": "ELmlIHLf910S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "pSNno2xlvoJU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Book_Rec/books_with_blurbs_clean.csv')"
      ],
      "metadata": {
        "id": "MB79hYu7gF0Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now that we have the data cleaned and saved to Drive we can use tfidf to convert our text data to numerical"
      ],
      "metadata": {
        "id": "EhN8U2qXgb_j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Kxfk7UzP79SA"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ApMQiprV79SA"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['blurb_clean_title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Q_LvF_jz79SB"
      },
      "outputs": [],
      "source": [
        "def most_similiar_book():\n",
        "  sentence = [input(\"Write a line from your favorite book? \")]\n",
        "  y = vectorizer.transform(sentence)\n",
        "  cosine_sim = cosine_similarity(X,y)\n",
        "  max_index = np.argmax(cosine_sim)\n",
        "  return print('\\n', 'Title:', '\\n', df['Title'].iloc[max_index], '\\n\\n', 'Description:', '\\n', df['Blurb'].iloc[max_index])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_similiar_book()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfrQy7BgOcpb",
        "outputId": "38cdf760-568d-4bae-b129-a093301b69fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a line from your favorite book? hello\n",
            "\n",
            " Title: \n",
            " Exegesis (Vintage Contemporaries) \n",
            "\n",
            " Description: \n",
            " -----------,Hello, Alice.,------------------------------------------------------------------,Date: Sun, 16 Jan 2000 14:27:39 (PST),From: edgar@cyprus.stanford.edu,To: Alice@cs.stanford.edu,Subject: Hello ,------------------------------------------------------------------,Hello, Alice.,      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TOP N Number of book reccomendations"
      ],
      "metadata": {
        "id": "uVnhosOEKDn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_n_similiar_books():\n",
        "  \n",
        "  n = int(input(\"How many books would you like reccomended? Please input a number. \"))\n",
        "\n",
        "  sentence = [input(\"Write the title or line from your favorite book? \")]\n",
        "  \n",
        "  y = vectorizer.transform(sentence)\n",
        "  \n",
        "  cosine_sim = cosine_similarity(X,y)\n",
        "\n",
        "  # Get the pairwsie similarity scores\n",
        "  sim_scores = list(enumerate(cosine_sim))\n",
        "  # Sort the books based on the similarity scores\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "  # Get the scores for n most similar books\n",
        "  sim_scores = sim_scores[0:n]\n",
        "  \n",
        "  titles = []\n",
        "  author = []\n",
        "  desc = []\n",
        "\n",
        "  for pair in sim_scores:\n",
        "    indx, score = pair\n",
        "    titles.append(df[\"Title\"][indx])\n",
        "    author.append(df[\"Author\"][indx])\n",
        "    desc.append(df[\"Blurb\"][indx])\n",
        "  \n",
        "  reccs = pd.DataFrame(list(zip(titles, author, desc)), columns =['titles', 'author', 'blurbs'])\n",
        "  \n",
        "  return reccs"
      ],
      "metadata": {
        "id": "0hJaJzKPKBQY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_similiar_books()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "cJPsESdULQxF",
        "outputId": "dc762c06-24d5-401c-f42f-464933fe3fa9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many books would you like reccomended? Please input a number. 2\n",
            "Write the title or line from your favorite book? Crows\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles         author  \\\n",
              "0  Crows and Jays: A Guide to the Crows, Jays and...    Steve Madge   \n",
              "1                              Still Life With Crows  Lincoln Child   \n",
              "\n",
              "                                              blurbs  \n",
              "0  London, 1676: when spy-turned-playwright Aphra...  \n",
              "1   A small Kansas town has turned into a killing...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a075559c-1e1e-47dc-8ddb-9feb248bbbe9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>author</th>\n",
              "      <th>blurbs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Crows and Jays: A Guide to the Crows, Jays and...</td>\n",
              "      <td>Steve Madge</td>\n",
              "      <td>London, 1676: when spy-turned-playwright Aphra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Still Life With Crows</td>\n",
              "      <td>Lincoln Child</td>\n",
              "      <td>A small Kansas town has turned into a killing...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a075559c-1e1e-47dc-8ddb-9feb248bbbe9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a075559c-1e1e-47dc-8ddb-9feb248bbbe9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a075559c-1e1e-47dc-8ddb-9feb248bbbe9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/internetarchive/openlibrary-client.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpf9ppZXguKe",
        "outputId": "bbfb9d8f-c2e6-4e3c-d6f6-99a697ea3092"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/internetarchive/openlibrary-client.git\n",
            "  Cloning https://github.com/internetarchive/openlibrary-client.git to /tmp/pip-req-build-x4lhydpf\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/internetarchive/openlibrary-client.git /tmp/pip-req-build-x4lhydpf\n",
            "  Resolved https://github.com/internetarchive/openlibrary-client.git to commit 61ce9703c10ef06cef745ff50915a9e86ddd5451\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting backoff==2.2.1\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting internetarchive==3.3.0\n",
            "  Downloading internetarchive-3.3.0.tar.gz (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonpickle==3.0.1\n",
            "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema==4.17.3\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests[security]==2.28.2\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson==3.18.3\n",
            "  Downloading simplejson-3.18.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt<0.7.0,>=0.6.0\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonpatch>=0.4\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.8/dist-packages (from internetarchive==3.3.0->openlibrary-client==0.0.31) (2.25.1)\n",
            "Collecting schema>=0.4.0\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from internetarchive==3.3.0->openlibrary-client==0.0.31) (4.64.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.8/dist-packages (from internetarchive==3.3.0->openlibrary-client==0.0.31) (1.26.14)\n",
            "Collecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema==4.17.3->openlibrary-client==0.0.31) (5.12.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema==4.17.3->openlibrary-client==0.0.31) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema==4.17.3->openlibrary-client==0.0.31) (22.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[security]==2.28.2->openlibrary-client==0.0.31) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[security]==2.28.2->openlibrary-client==0.0.31) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests[security]==2.28.2->openlibrary-client==0.0.31) (3.0.1)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema==4.17.3->openlibrary-client==0.0.31) (3.15.0)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.8/dist-packages (from schema>=0.4.0->internetarchive==3.3.0->openlibrary-client==0.0.31) (0.5.5)\n",
            "Building wheels for collected packages: openlibrary-client, internetarchive, docopt\n",
            "  Building wheel for openlibrary-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openlibrary-client: filename=openlibrary_client-0.0.31-py2.py3-none-any.whl size=41638 sha256=b89bf9eb0fb2c0fbd7bc7ee78245361f29b6e0a08e662fddaf13a2f9b4aaeb21\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eyb6d14q/wheels/e4/74/7a/47e49becc10d1cdc7197740970d8239aeb656aaa290e09305d\n",
            "  Building wheel for internetarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for internetarchive: filename=internetarchive-3.3.0-py3-none-any.whl size=94907 sha256=cefd8795cd52e838201fb7f3d4e349ae2d750d97b047d2e1088f382019a06fc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/6c/71/63b6eea65399858ee07585aed2e20fc949a67d1914565c95f9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=8f9c961068a5e25d821eab3a944cb803c821bad2b2b90db29bf481c117858bda\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built openlibrary-client internetarchive docopt\n",
            "Installing collected packages: docopt, simplejson, schema, requests, pkgutil-resolve-name, jsonpointer, jsonpickle, backoff, jsonschema, jsonpatch, internetarchive, openlibrary-client\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "Successfully installed backoff-2.2.1 docopt-0.6.2 internetarchive-3.3.0 jsonpatch-1.32 jsonpickle-3.0.1 jsonpointer-2.3 jsonschema-4.17.3 openlibrary-client-0.0.31 pkgutil-resolve-name-1.3.10 requests-2.28.2 schema-0.7.5 simplejson-3.18.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from olclient.openlibrary import OpenLibrary\n",
        "ol = OpenLibrary()\n",
        "author_olid = ol.Author.get_olid_by_name('Dan Brown')\n",
        "author_obj = ol.get(author_olid)"
      ],
      "metadata": {
        "id": "jo8MLNR2g5pZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "EilQjc_OiiXt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similiar_book():\n",
        "  sentence = [input(\"Write a line from your favorite book? \")]\n",
        "  y = vectorizer.transform(sentence)\n",
        "  cosine_sim = cosine_similarity(X,y)\n",
        "  max_index = np.argmax(cosine_sim)\n",
        "  author_olid = ol.Author.get_olid_by_name(df['Author'].iloc[max_index])\n",
        "  if ol.get(author_olid) != None:\n",
        "    author_obj = ol.get(author_olid)\n",
        "  else:\n",
        "    print('Sorry author is not in our database')\n",
        "  if author_obj.bio != None:\n",
        "    author_desc = author_obj.bio.split('\\r\\n\\r\\n')[0]\n",
        "  else:\n",
        "    author_desc = f\"Sorry we dont have any information about {df['Author'].iloc[max_index]} at the moment\"\n",
        "  return print('\\n', 'Title:', '\\n', df['Title'].iloc[max_index], '\\n\\n', 'Description:', '\\n', df['Blurb'].iloc[max_index], '\\n\\n', 'About the Author:', '\\n', author_desc, \n",
        "               display(HTML('<img src=\"https://covers.openlibrary.org/b/isbn/' + df['ISBN'].iloc[max_index] + '-L.jpg\" />')))"
      ],
      "metadata": {
        "id": "IkNoiogZmKLx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similiar_book()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "RM07JIzKp0fk",
        "outputId": "8f5103bd-f3d3-42c2-93e4-a5c9bcbbb904"
      },
      "execution_count": 21,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write a line from your favorite book? crow\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"https://covers.openlibrary.org/b/isbn/0689860145-L.jpg\" />"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Title: \n",
            " Seven Crows  (Buffy the Vampire Slayer and Angel) \n",
            "\n",
            " Description: \n",
            " \"One crow sorrow, Two crows mirth,,Three crows a wedding,,Four crows a birth,,Five crows silver,,Six crows gold,,Seven crows a secret,,Which must never be told....\",In a sleepy little town on the border between Arizona and Mexico, Agent Riley Finn and his operative wife, Sam, have tracked down an international smuggling ring involving vampires. Surprisingly the call for reinforcements is answered by Buffy Summers and the atoning vampire Angel.,Now tempers are flaring in the heat of the day -- and night -- as people are dying and locals are turning a blind eye to the deadly events. Bodies are turning up in the surrounding desert, some drained of blood, some having succumbed to another, fast-moving death. Riley Finn is noticing the arrival of more and more crows to this area, ominous portents of the events ahead. But even Mr. Secret Agent Man is distracted from his job when his wife goes undercover with Angel.... \n",
            "\n",
            " About the Author: \n",
            " John Blair Vornholt (born February 14, 1951) is an American author, screenwriter and journalist. None\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 ('tf_2.7')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "44588579933afcba3dd84e72417e746017e151b615ee068807749488be21dd91"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}