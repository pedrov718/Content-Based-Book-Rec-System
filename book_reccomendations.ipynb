{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pedrov718/Content-Based-Book-Rec-System/blob/main/book_reccomendations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlGgnvfj79R8",
        "outputId": "6c1e992f-c089-4948-8eee-6392b8115474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import numpy as np\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ahHQOMF79R-"
      },
      "outputs": [],
      "source": [
        "df  = pd.read_csv('/content/drive/MyDrive/Book Rec/books_with_blurbs.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDGvHv__79R-"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLUla0u079R-"
      },
      "outputs": [],
      "source": [
        "df['Blurb'][10:15]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8O4DSRj79R-"
      },
      "outputs": [],
      "source": [
        "# Load spacy\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "def clean_string(text, stem=\"None\"):\n",
        "\n",
        "    final_string = \"\"\n",
        "\n",
        "    # Make lower\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove line breaks\n",
        "    text = re.sub(r'\\n', '', text)\n",
        "\n",
        "    # Remove puncuation\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    #Remove stop words\n",
        "    text = text.split()\n",
        "\n",
        "    #Remove numbers\n",
        "    text_filtered = [re.sub(r'\\w*\\d\\w*', '', word) for word in text]\n",
        "\n",
        "    # Stem or Lemmatize\n",
        "    if stem == 'Stem':\n",
        "        stemmer = PorterStemmer() \n",
        "        text_stemmed = [stemmer.stem(y) for y in text_filtered]\n",
        "    elif stem == 'Lem':\n",
        "        lem = WordNetLemmatizer()\n",
        "        text_stemmed = [lem.lemmatize(y) for y in text_filtered]\n",
        "    elif stem == 'Spacy':\n",
        "        text_filtered = nlp(' '.join(text_filtered))\n",
        "        text_stemmed = [y.lemma_ for y in text_filtered]\n",
        "    else:\n",
        "        text_stemmed = text_filtered\n",
        "\n",
        "    final_string = ' '.join(text_stemmed)\n",
        "\n",
        "    return final_string\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQdeiD6j79R_"
      },
      "outputs": [],
      "source": [
        "print(\"Cleaning train data...\\n\")\n",
        "\n",
        "df[\"blurb_clean\"] = df['Blurb'].apply(lambda x: clean_string(x, stem='Spacy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85K4qCwD79R_"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bh3dupB79R_"
      },
      "outputs": [],
      "source": [
        "df['Title_lower'] = df['Title'].apply(lambda x: x.lower())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEbwj1nx79SA"
      },
      "outputs": [],
      "source": [
        "df['blurb_clean_title'] =  df['Title_lower'] +  ' ' + df['blurb_clean']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RbrbPNn79SA"
      },
      "outputs": [],
      "source": [
        "df['blurb_clean_title'][10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas"
      ],
      "metadata": {
        "id": "cvCgzyhj9ml2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/Book Rec/books_with_blurbs_clean.csv')"
      ],
      "metadata": {
        "id": "PFA3HeEFf4d_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "b0a46ae9-f1ab-4b89-c4b8-1dba840dace8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-abb7f376ddfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Book Rec/books_with_blurbs_clean.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CuFno2I491Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run locally here"
      ],
      "metadata": {
        "id": "ELmlIHLf910S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Book_Rec/books_with_blurbs_clean.csv')"
      ],
      "metadata": {
        "id": "MB79hYu7gF0Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now that we have the data cleaned and saved to Drive we can use tfidf to convert our text data to numerical"
      ],
      "metadata": {
        "id": "EhN8U2qXgb_j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Kxfk7UzP79SA"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ApMQiprV79SA"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['blurb_clean_title'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q_LvF_jz79SB"
      },
      "outputs": [],
      "source": [
        "def most_similiar_book():\n",
        "  sentence = [input(\"Write a line from your favorite book? \")]\n",
        "  y = vectorizer.transform(sentence)\n",
        "  cosine_sim = cosine_similarity(X,y)\n",
        "  max_index = np.argmax(cosine_sim)\n",
        "  return print('\\n', 'Title:', '\\n', df['Title'].iloc[max_index], '\\n\\n', 'Description:', '\\n', df['Blurb'].iloc[max_index])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "most_similiar_book()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "xfrQy7BgOcpb",
        "outputId": "3de66e8d-2d8e-4de4-8f73-867fb04b09af"
      },
      "execution_count": 27,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write a line from your favorite book? baos\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"https://covers.openlibrary.org/b/isbn/0060973129-L.jpg\" />"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Title: \n",
            " Decision in Normandy \n",
            "\n",
            " Description: \n",
            " Here, for the first time in paperback, is an outstanding military history that offers a dramatic new perspective on the Allied campaign that began with the invasion of the D-Day beaches of Normandy. Nationa advertising in Military History. \n",
            "\n",
            " About the Author: \n",
            " Sorry we dont have any information about Carlo D'Este at the moment None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TOP N Number of book reccomendations"
      ],
      "metadata": {
        "id": "uVnhosOEKDn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_n_similiar_books():\n",
        "  \n",
        "  n = int(input(\"How many books would you like reccomended? Please input a number. \"))\n",
        "\n",
        "  sentence = [input(\"Write the title or line from your favorite book? \")]\n",
        "  \n",
        "  y = vectorizer.transform(sentence)\n",
        "  \n",
        "  cosine_sim = cosine_similarity(X,y)\n",
        "\n",
        "  # Get the pairwsie similarity scores\n",
        "  sim_scores = list(enumerate(cosine_sim))\n",
        "  # Sort the books based on the similarity scores\n",
        "  sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "  # Get the scores for n most similar books\n",
        "  sim_scores = sim_scores[0:n]\n",
        "  \n",
        "  titles = []\n",
        "  author = []\n",
        "  desc = []\n",
        "\n",
        "  for pair in sim_scores:\n",
        "    indx, score = pair\n",
        "    titles.append(df[\"Title\"][indx])\n",
        "    author.append(df[\"Author\"][indx])\n",
        "    desc.append(df[\"Blurb\"][indx])\n",
        "  \n",
        "  reccs = pd.DataFrame(list(zip(titles, author, desc)), columns =['titles', 'author', 'blurbs'])\n",
        "  \n",
        "  return reccs"
      ],
      "metadata": {
        "id": "0hJaJzKPKBQY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_similiar_books()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "cJPsESdULQxF",
        "outputId": "89b8d6c9-6e6b-4a1c-dd1a-704d4c9bd8ca"
      },
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How many books would you like reccomended? Please input a number. 4\n",
            "Write the title or line from your favorite book? baos\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              titles            author  \\\n",
              "0                               Decision in Normandy      Carlo D'Este   \n",
              "1  Flu: The Story of the Great Influenza Pandemic...  Gina Bari Kolata   \n",
              "2                             The Kitchen God's Wife           Amy Tan   \n",
              "3  What If?: The World's Foremost Military Histor...     Robert Cowley   \n",
              "\n",
              "                                              blurbs  \n",
              "0  Here, for the first time in paperback, is an o...  \n",
              "1  The fascinating, true story of the world's dea...  \n",
              "2  Winnie and Helen have kept each others worst s...  \n",
              "3  Historians and inquisitive laymen alike love t...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d7492a9-f8e5-4c92-ba82-8a66a6935576\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titles</th>\n",
              "      <th>author</th>\n",
              "      <th>blurbs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Decision in Normandy</td>\n",
              "      <td>Carlo D'Este</td>\n",
              "      <td>Here, for the first time in paperback, is an o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
              "      <td>Gina Bari Kolata</td>\n",
              "      <td>The fascinating, true story of the world's dea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Kitchen God's Wife</td>\n",
              "      <td>Amy Tan</td>\n",
              "      <td>Winnie and Helen have kept each others worst s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What If?: The World's Foremost Military Histor...</td>\n",
              "      <td>Robert Cowley</td>\n",
              "      <td>Historians and inquisitive laymen alike love t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d7492a9-f8e5-4c92-ba82-8a66a6935576')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d7492a9-f8e5-4c92-ba82-8a66a6935576 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d7492a9-f8e5-4c92-ba82-8a66a6935576');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/internetarchive/openlibrary-client.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kpf9ppZXguKe",
        "outputId": "c1909b77-00de-4cc8-cf57-0268983b0b73"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/internetarchive/openlibrary-client.git\n",
            "  Cloning https://github.com/internetarchive/openlibrary-client.git to /tmp/pip-req-build-u9f93avx\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/internetarchive/openlibrary-client.git /tmp/pip-req-build-u9f93avx\n",
            "  Resolved https://github.com/internetarchive/openlibrary-client.git to commit 2367838042ccda2e0ddd16ed75b2e2cafac016b6\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting backoff==2.2.1\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting internetarchive==3.3.0\n",
            "  Downloading internetarchive-3.3.0.tar.gz (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 KB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonpickle==3.0.1\n",
            "  Downloading jsonpickle-3.0.1-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonschema==4.17.3\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 KB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests[security]==2.28.2\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 KB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson==3.18.2\n",
            "  Downloading simplejson-3.18.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/135.5 KB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt<0.7.0,>=0.6.0\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonpatch>=0.4\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.8/dist-packages (from internetarchive==3.3.0->openlibrary-client==0.0.31) (2.25.1)\n",
            "Collecting schema>=0.4.0\n",
            "  Downloading schema-0.7.5-py2.py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tqdm>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from internetarchive==3.3.0->openlibrary-client==0.0.31) (4.64.1)\n",
            "Collecting urllib3>=1.26.0\n",
            "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema==4.17.3->openlibrary-client==0.0.31) (5.10.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema==4.17.3->openlibrary-client==0.0.31) (22.2.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from jsonschema==4.17.3->openlibrary-client==0.0.31) (0.19.3)\n",
            "Collecting pkgutil-resolve-name>=1.3.10\n",
            "  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[security]==2.28.2->openlibrary-client==0.0.31) (2.10)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests[security]==2.28.2->openlibrary-client==0.0.31) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[security]==2.28.2->openlibrary-client==0.0.31) (2022.12.7)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources>=1.4.0->jsonschema==4.17.3->openlibrary-client==0.0.31) (3.12.1)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: contextlib2>=0.5.5 in /usr/local/lib/python3.8/dist-packages (from schema>=0.4.0->internetarchive==3.3.0->openlibrary-client==0.0.31) (0.5.5)\n",
            "Building wheels for collected packages: openlibrary-client, internetarchive, docopt\n",
            "  Building wheel for openlibrary-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openlibrary-client: filename=openlibrary_client-0.0.31-py2.py3-none-any.whl size=41605 sha256=bd4f0d8519f28385e25b4d90a3266a59523fd430e201687781cb114d5e612eb4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i0fcc8d9/wheels/e4/74/7a/47e49becc10d1cdc7197740970d8239aeb656aaa290e09305d\n",
            "  Building wheel for internetarchive (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for internetarchive: filename=internetarchive-3.3.0-py3-none-any.whl size=94907 sha256=2d80bb52cf136e0804016c884f8046809e3061146eeb16e22085f9a81bde728e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/6c/71/63b6eea65399858ee07585aed2e20fc949a67d1914565c95f9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=b2ce00e66aa6b53f023ca3b3f04193576a57362b7fc1dce1c8fc0e33f77155c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n",
            "Successfully built openlibrary-client internetarchive docopt\n",
            "Installing collected packages: docopt, urllib3, simplejson, schema, pkgutil-resolve-name, jsonpointer, jsonpickle, backoff, requests, jsonschema, jsonpatch, internetarchive, openlibrary-client\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.25.1\n",
            "    Uninstalling requests-2.25.1:\n",
            "      Successfully uninstalled requests-2.25.1\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "Successfully installed backoff-2.2.1 docopt-0.6.2 internetarchive-3.3.0 jsonpatch-1.32 jsonpickle-3.0.1 jsonpointer-2.3 jsonschema-4.17.3 openlibrary-client-0.0.31 pkgutil-resolve-name-1.3.10 requests-2.28.2 schema-0.7.5 simplejson-3.18.2 urllib3-1.26.14\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests",
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from olclient.openlibrary import OpenLibrary\n",
        "ol = OpenLibrary()\n",
        "author_olid = ol.Author.get_olid_by_name('Dan Brown')\n",
        "author_obj = ol.get(author_olid)"
      ],
      "metadata": {
        "id": "jo8MLNR2g5pZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "EilQjc_OiiXt"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similiar_book():\n",
        "  sentence = [input(\"Write a line from your favorite book? \")]\n",
        "  y = vectorizer.transform(sentence)\n",
        "  cosine_sim = cosine_similarity(X,y)\n",
        "  max_index = np.argmax(cosine_sim)\n",
        "  author_olid = ol.Author.get_olid_by_name(df['Author'].iloc[max_index])\n",
        "  if ol.get(author_olid) != None:\n",
        "    author_obj = ol.get(author_olid)\n",
        "  else:\n",
        "    print('Sorry author is not in our database')\n",
        "  if author_obj.bio != None:\n",
        "    author_desc = author_obj.bio.split('\\r\\n\\r\\n')[0]\n",
        "  else:\n",
        "    author_desc = f\"Sorry we dont have any information about {df['Author'].iloc[max_index]} at the moment\"\n",
        "  return print('\\n', 'Title:', '\\n', df['Title'].iloc[max_index], '\\n\\n', 'Description:', '\\n', df['Blurb'].iloc[max_index], '\\n\\n', 'About the Author:', '\\n', author_desc, \n",
        "               display(HTML('<img src=\"https://covers.openlibrary.org/b/isbn/' + df['ISBN'].iloc[max_index] + '-L.jpg\" />')))"
      ],
      "metadata": {
        "id": "IkNoiogZmKLx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "most_similiar_book()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "id": "RM07JIzKp0fk",
        "outputId": "5f0f0b03-f555-4dde-d476-d49bee681865"
      },
      "execution_count": 37,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write a line from your favorite book? a murder of crows\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<img src=\"https://covers.openlibrary.org/b/isbn/031201483X-L.jpg\" />"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Title: \n",
            " A Murder of Crows \n",
            "\n",
            " Description: \n",
            " Ingrid Langley had endured a divorce from her husband, Patrick, and never intended to see him again. But Patrick was desperate; as an agent for British Intelligence, he needed a woman to be his cover. And how could Ingrid refuse--when he was investigating the murder of her second husband? Martin's. \n",
            "\n",
            " About the Author: \n",
            " Sorry we dont have any information about Margaret Duffy at the moment None\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 ('tf_2.7')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "44588579933afcba3dd84e72417e746017e151b615ee068807749488be21dd91"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}